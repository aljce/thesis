\documentclass[./Thesis.tex]{subfiles}
\begin{document}

\chapter{Termination}
\label{chap:termination}

\epigraph{
  What can be asserted without evidence can also be dismissed without evidence.
}{Christopher Hitchens \cite{hitchens-quote}}

\begin{code}[hide]
  module Termination where
  open import Relation.Nullary using (Â¬_)
  open import Relation.Nullary.Decidable using (False)
  open import Relation.Nullary.Negation using (contradiction)
  open import Data.Empty using (âŠ¥)
  open import AKS.Nat using (â„•; zero; suc; _âˆ¸_; _*_; _<_; _â‰¤_; lte; _â‰Ÿ_)
  open import AKS.Nat using (+-comm; suc-injective-â‰¡; nâ‰®0; 0â‰¤n; n<1+n; â‰¤-refl) renaming (nâ‰¤mâ‡’n<mâŠŽnâ‰¡m to nâ‰¤mâ‡’n<mâˆ¨nâ‰¡m)
  open import Data.Sum using () renaming (injâ‚ to orâ‚; injâ‚‚ to orâ‚‚)
  open import AKS.Binary using (ð”¹âº)
  open ð”¹âº
  open import AKS.Nat.Divisibility using (_div_; Euclidean; Euclideanâœ“)
  open Euclidean using () renaming (q to quotient)
  open import Relation.Binary.PropositionalEquality
    using (_â‰¡_; _â‰¢_; module â‰¡-Reasoning)
    renaming (refl to â‰¡-refl; sym to â‰¡-sym; cong to â‰¡-cong; congâ‚‚ to â‰¡-congâ‚‚)
  open â‰¡-Reasoning
  open import Data.Unit using (tt)
  open import Polynomial.Simple.AlmostCommutativeRing.Instances using (module Nat)
  open import Polynomial.Simple.Reflection using (solve)
  open Nat.Reflection using (âˆ€âŸ¨_âŸ©)
  open import Data.List using ([]; _âˆ·_; List)
  open import Function using (_$_)
  open import AKS.Unsafe using (BOTTOM)
\end{code} % $
\section{A Correctness Interlude}
\label{sec:a-correctness-interlude}
The previous chapter omitted a critical flaw in its analysis. The code below is
rejected by the \Agda{} compiler. The compiler's \textit{termination checker} \cite{agda}
fails as \Agda{} can not infer that the result of non-zero integer division by
$2$ always returns an integer strictly smaller than the input. The termination
checker ensures than every function is total. In other words,
the termination checker disallows infinite loops. This termination proof
is obvious but termination proofs can quickly become complex. In general checking
termination, commonly called the halting problem, is undecidable. 
\begin{code}[hide]
  module Badâ‚ where
    {-# TERMINATING #-}
\end{code}
\begin{code}
    âŸ¦_â‡‘âŸ§âº : âˆ€ (n : â„•) {â‰¢0 : False (n â‰Ÿ 0)} â†’ ð”¹âº
    âŸ¦ suc n â‡‘âŸ§âº with suc n div 2
    ... | Euclideanâœ“ (suc q) 0 _ _ = âŸ¦ suc q â‡‘âŸ§âº 0áµ‡
    ... | Euclideanâœ“ zero    1 _ _ = ð•“1áµ‡
    ... | Euclideanâœ“ (suc q) 1 _ _ = âŸ¦ suc q â‡‘âŸ§âº 1áµ‡
\end{code}
This checker is a keystone of the correctness of the logic of \Agda{}. Consider
the following function with a similar call graph. Instead of the input
decreasing to some base case it doubles with every recursive call. This function can
be used to prove falsehood, thus a logic with unconstrained recursion is
inconsistent.
\begin{code}[hide]
  module Badâ‚‚ where
    {-# TERMINATING #-}
\end{code}
\begin{code}
    increasing : â„• â†’ âŠ¥
    increasing n with 2 * n
    ... | q = increasing q

    false : âŠ¥
    false = increasing 0
\end{code}
In fact, the example above can be simplified in the code below. In English
this code expresses the famous fallacy of circular reasoning ``false is true
because false is true''.
\begin{code}[hide]
  module Badâ‚ƒ where
    {-# TERMINATING #-}
\end{code}
\begin{code}
    false : âŠ¥
    false = false
\end{code}
Thankfully none of these false expressions are accepted by the \Agda{} compiler.
This begs the question how does \Agda{} determine which recursive functions to
accept? Unfortunately the \Agda{} compiler can not solve the halting problem so
it must be restrictive. The compiler only accepts recursive
calls that are \textit{structurally decreasing}, a small
subset of the set of recursive functions. A recursive call is structurally
decreasing if the call occurs on a strict sub expression \cite{agda}. The
expression $\AgdaInductiveConstructor{suc} \, n$ is a strict sub-expression of
$\AgdaInductiveConstructor{suc} \,
  (\AgdaInductiveConstructor{suc} \,
    (\AgdaInductiveConstructor{suc} \, n))
$,
but $\AgdaInductiveConstructor{suc} \, n$ is not a strict sub-expression of
$\AgdaInductiveConstructor{suc} \, n$.
Addition, our first example of recursion, is acceptable as
$n <_{sub} \AgdaInductiveConstructor{suc} \, n$.
\begin{code}[hide]
  module Add where
\end{code}
\begin{code}
    _+_ : â„• â†’ â„• â†’ â„•
    zero + m = m
    (suc n) + m = suc (n + m)
\end{code}
\begin{code}[hide]
  open import AKS.Nat using (_+_)
\end{code}
The following inductive definition of the Fibonacci function
has structurally decreasing calls as
$\AgdaInductiveConstructor{suc} \, n <_{sub} \AgdaInductiveConstructor{suc} \, (\AgdaInductiveConstructor{suc} \, n)$
and
$n <_{sub} \AgdaInductiveConstructor{suc} \, (\AgdaInductiveConstructor{suc} \, n)$.
\begin{code}
  fib : â„• â†’ â„•
  fib zero = 0
  fib (suc zero) = 1
  fib (suc (suc n)) = fib (suc n) + fib n
\end{code}
So far all the recursive functions described have been
\textit{primitive recursive} \cite{soare}. This is a large class, but the set of
structurally decreasing functions is larger than the set of primitive
recursive functions. The Ackerrmann function is the canonical example of
function which is not primitive recursive.
\begin{code}
  ack : â„• â†’ â„• â†’ â„•
  ack zero m = suc m
  ack (suc n) zero = ack n (suc zero)
  ack (suc n) (suc m) = ack n (ack (suc n) m)
\end{code}
\Agda{} accepts this definition as the recursive
calls are decreasing lexicographically.
The recursive call in the second case decreases in the first argument so
the second argument increasing is acceptable
$
(n, \, \AgdaInductiveConstructor{suc} \, \AgdaInductiveConstructor{zero})
<_{sub}
(\AgdaInductiveConstructor{suc} \, n, \, \AgdaInductiveConstructor{zero})
$.
For a similar reason the outer call in the third case is acceptable
$
(n, \, \AgdaFunction{ack} \, (\AgdaInductiveConstructor{suc} \, n) \, m)
<_{sub}
(\AgdaInductiveConstructor{suc} \, n, \, \AgdaInductiveConstructor{suc} \, m)
$.
The inner call is acceptable as the second argument decreases while the first
stays constant, this is lexicographic order
$
(\AgdaInductiveConstructor{suc} \, n, \, m)
<_{sub}
(\AgdaInductiveConstructor{suc} \, n, \, \AgdaInductiveConstructor{suc} \, m)
$. \\
\section{Well-Founded Relations}
\label{sec:well-founded-relations}
An astute reader may have noticed a pattern. \Agda{} accepts your recursive
definition if it can infer a structural \textit{well-founded relation}
\cite{soare}. A well-founded relation is a binary relation $\prec$ that has no
infinitely descending chains $\dots \prec x_k \prec \dots \prec x_1 \prec x_0$.
For instance the strict ordering over the naturals is well-founded
as every chain will eventually reach $0$.
\begin{align}
  \label{eqn:wellfounded-natural}
  0 < 1 < 2 < 3 < 4 < 5
\end{align}
The non-strict ordering is not well-founded as an infinite chain of the
reflexivity axiom can be constructed.
\begin{align}
  \label{eqn:non-wellfounded-natural}
  \dots \leq 0 \leq \dots \leq 0 \leq 0
\end{align}
Unfortunately, these relation chains do not capture the full structure of well-founded
relations. A well-founded relation often has multiple elements that could be
appended to the chain. This idea is illustrated in the well-founded tree
rooted at 3 found in figure \ref{fig:wellfounded-tree}.
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \Tree
    [.3
      {$0 < 3$}
      [.{$1 < 3$}
        {$0 < 1$}
      ]
      [.{$2 < 3$}
        {$0 < 2$}
        [.{$1 < 2$}
          {$0 < 1$}
        ]
      ]
    ]
  \end{tikzpicture}
  \caption{A well-founded tree }
  \label{fig:wellfounded-tree}
\end{figure}
These trees encapsulate the full structure of a well-ordering relation.
Therefore, if we could express this tree as an \Agda{} datatype, we could supply
our own well-ordering relation even when \Agda{} can not infer it. The final
datatype that represents well-founded trees is somewhat puzzling at first
glance. So to introduce it we start with a sensible datatype and make small
changes to the definition until we have reached the correct representation.
These trees are general trees, trees that can have an arbitrary number
of children. They are often called rose trees in functional programming
literature. They make for a good starting datatype.
\begin{code}[hide]
  module Treeâ‚ where
\end{code}
\begin{code}
    data RoseTree : Set where
      Node : List RoseTree â†’ RoseTree
\end{code}
We then apply a \textit{continuation passing style} \cite{harper} transformation to the
recursive call. Instead of having a list of children we have a continuation that
can be invoked with the index of the requested child.
\begin{code}[hide]
  module Treeâ‚‚ where
\end{code}
\begin{code}
    data RoseTree : Set where
      Node : (â„• â†’ RoseTree) â†’ RoseTree
\end{code}
Unfortunately, this makes our definition unusable as now every rose tree must have
infinite size. From a \textit{game theotertic} perspective, a consumer may request
the first child of every node repetitively.
\begin{code}
    rosetree-uninhabited : RoseTree â†’ âŠ¥
    rosetree-uninhabited (Node children) = rosetree-uninhabited (children 0)
\end{code}
Any well founded tree is necessarily finite as each node always has a finite
number of children ``less'' than itself. We can solve this by adding an upper
bound and ensuring that any index is less than the bound.
\begin{code}[hide]
  module Treeâ‚ƒ where
\end{code}
\begin{code}
    data RoseTree (bound : â„•) : Set where
      Node : (âˆ€ {lower : â„•} â†’ lower < bound â†’ RoseTree lower)
           â†’ RoseTree bound
\end{code}
Note that the definition above does not make use of any properties specific to
natural numbers. The definition simply requires a binary relation.
By parameterizing the datatype by the relation we
arrive at our finial definition. This is often called the accessibility
predicate so we update the names accordingly.
\begin{code}
  data Acc {A : Set} (_â‰º_ : A â†’ A â†’ Set) (bound : A) : Set where
    acc : (âˆ€ {lower : A} â†’ lower â‰º bound â†’ Acc _â‰º_ lower)
        â†’ Acc _â‰º_ bound
\end{code}
Continuing with the game theoretic analysis proving a relation is well-founded
for a specific bound is a simple game. A game where the prover
continually asks for a lower bound and wins when it is impossible for the
other player to supply a lower bound. This game plays out below for a bound of $3$.
\begin{code}
  3-well-founded : Acc _<_ 3
  3-well-founded = acc Î» lâ‚<3 â†’ acc Î» lâ‚‚<lâ‚ â†’ acc Î» lâ‚ƒ<lâ‚‚ â†’ acc Î» lâ‚„<lâ‚ƒ â†’
    contradiction lâ‚„<lâ‚ƒ (end lâ‚<3 lâ‚‚<lâ‚ lâ‚ƒ<lâ‚‚)
\end{code}
\begin{code}[hide]
    where
\end{code}
\begin{code}
    end : âˆ€ {lâ‚ lâ‚‚ lâ‚ƒ lâ‚„} â†’ lâ‚ < 3 â†’ lâ‚‚ < lâ‚ â†’ lâ‚ƒ < lâ‚‚ â†’ Â¬ (lâ‚„ < lâ‚ƒ)
    end {2} {1} {0} {lâ‚„} lâ‚<3 lâ‚‚<lâ‚ lâ‚ƒ<lâ‚‚ lâ‚„<lâ‚ƒ = contradiction lâ‚„<lâ‚ƒ nâ‰®0 
\end{code}
\section{Win Every Game}
\label{sec:win-every-game}
Now we turn to proving that any natural forms a rooted well-founded tree under the
strict ordering relation. Usually proving a property holds for any $n$ is harder
then proving that property holds for specific $n$. This concept applies to
proving that every natural is well-founded. Specifically our choice of
less than relation is poorly suited for this task. We will define an inductive
ordering relation and show that our original definition of ordering is a
subrelation of the inductive-definition. Then if the inductive definition is
well-founded the subrelation will be as well. This last idea is shown below.
\begin{code}[hide]
  module Subâ‚ where
\end{code}
\begin{code}
    subrelation
        : âˆ€ {A : Set} {_â‰ºâ‚_ _â‰ºâ‚‚_ : A â†’ A â†’ Set} {n}
        â†’ (âˆ€ {a b} â†’ a â‰ºâ‚‚ b â†’ a â‰ºâ‚ b)
        â†’ Acc _â‰ºâ‚_ n
        â†’ Acc _â‰ºâ‚‚_ n
    subrelation â‰ºâ‚‚â‡’â‰ºâ‚ (acc down) =
      acc Î» xâ‰ºâ‚‚n â†’ subrelation â‰ºâ‚‚â‡’â‰ºâ‚ (down (â‰ºâ‚‚â‡’â‰ºâ‚ xâ‰ºâ‚‚n))
\end{code}
Next we turn to the inductive ordering relation. The key idea behind this
definition is that each $\AgdaInductiveConstructor{â‰¤-step}$ constructor adds one
to the right bound. The base case is the reflexivity axiom so the number of
$\AgdaInductiveConstructor{â‰¤-step}$ constructors is the distance between the
left and right bound. The old definition internalizes this concept into the
definition as the $k$ in
$a \, \AgdaDatatype{â‰¤} \, b = a \, \AgdaFunction{+} \, k \, \AgdaDatatype{â‰¡} \, b$.
\begin{code}
    data _â‰¤â±_ (n : â„•) (m : â„•) : Set where
      â‰¤-same : n â‰¡ m â†’ n â‰¤â± m
      â‰¤-step : âˆ€ {o} â†’ suc o â‰¡ m â†’ n â‰¤â± o â†’ n â‰¤â± m

    _<â±_ : â„• â†’ â„• â†’ Set
    n <â± m = suc n â‰¤â± m

    2â‰¤â±4 : 2 â‰¤â± 4
    2â‰¤â±4 = â‰¤-step {o = 3} â‰¡-refl (â‰¤-step {o = 2} â‰¡-refl (â‰¤-same â‰¡-refl))
\end{code}
This concept also hints at how to show that the old definition is a subrelation
of the inductive definition. Count $k$ down to $0$ adding a
$\AgdaInductiveConstructor{â‰¤-step}$. We first transform
$a \, \AgdaFunction{+} \, k \, \AgdaDatatype{â‰¡} \, b$ into
$k \, \AgdaFunction{+} \, a \, \AgdaDatatype{â‰¡} \, b$ as $\AgdaFunction{\_+\_}$
is defined on the first argument. So it can simplify terms like
$0 \, \AgdaFunction{+} \, a$ into $a$ automatically.
\begin{code}
    â‰¤â‡’â‰¤â± : âˆ€ {a b} â†’ a â‰¤ b â†’ a â‰¤â± b
    â‰¤â‡’â‰¤â± {a} {b} (lte k a+kâ‰¡b) = loop a b k $ begin
      k + a â‰¡âŸ¨ +-comm k a âŸ© a + k â‰¡âŸ¨ a+kâ‰¡b âŸ© b âˆŽ
      where
      loop : âˆ€ a b k â†’ k + a â‰¡ b â†’ a â‰¤â± b
      loop a b zero 0+aâ‰¡b = â‰¤-same $ begin
        a â‰¡âŸ¨âŸ© 0 + a â‰¡âŸ¨ 0+aâ‰¡b âŸ© b âˆŽ
      loop a (suc b) (suc k) 1+k+aâ‰¡1+b = â‰¤-step â‰¡-refl $ loop a b k $ begin
        k + a â‰¡âŸ¨ suc-injective-â‰¡ 1+k+aâ‰¡1+b âŸ© b âˆŽ
\end{code}
\begin{code}
    <â‡’<â± : âˆ€ {a b} â†’ a < b â†’ a <â± b
    <â‡’<â± {a} {b} a<b = â‰¤â‡’â‰¤â± {suc a} {b} a<b
\end{code}
Next we need to prove that any natural forms a rooted well-founded tree under
the inductively defined ordering. This requires a set of mutually recursive
functions.
\begin{code}
    <â±-well-founded : âˆ€ {n} â†’ Acc _<â±_ n
    <â±-count-down : âˆ€ {m n} â†’ m <â± n â†’ Acc _<â±_ m
\end{code}
The first accepts the ``player'' supplied proof that some number $m$
is less than the bound. Then the second function counts $n$ down to $m$ until
they are equal. Then it asks the player for a proof that there is some number
smaller than $m$. Note that every case in $\AgdaFunction{<â±-count-down}$ peals
off exactly one $\AgdaFunction{suc}$ so \Agda{} is able to infer that the
functions are structurally decreasing.
\begin{code}
    <â±-well-founded {n} = acc (Î» x<â±n â†’ <â±-count-down x<â±n)
    <â±-count-down {m} {suc .m} (â‰¤-same â‰¡-refl) = <â±-well-founded {m}
    <â±-count-down {m} {suc n} (â‰¤-step â‰¡-refl mâ‰¤n) = <â±-count-down {m} {n} mâ‰¤n
\end{code}
Lastly we bring all the puzzle pieces together and prove that our original
definition of ordering is well founded.
\begin{code}
    <-well-founded : âˆ€ {n} â†’ Acc _<_ n
    <-well-founded {n} = subrelation <â‡’<â± <â±-well-founded
\end{code}
\begin{code}[hide]
  open Subâ‚ using (<-well-founded)
\end{code}
\section{Lie No More}
\label{sec:lie-no-more}
Now we can return to our function that upcasts a natural number to a binary
encoded number. In order to use the mechanism developed above we must first
prove a lemma that integer division by $2$ is strictly less than the input.
Thankfully this lemma is simple enough for an automated ring solver to prove.
\begin{code}
  div-< : âˆ€ n q r {qâ‰¢0 : False (q â‰Ÿ 0)} â†’ n â‰¡ r + 2 * q â†’ q < n
\end{code}
\begin{code}[hide]
  div-< n (suc q) r â‰¡-refl = lte (q + r) (âˆ€âŸ¨ q âˆ· r âˆ· [] âŸ©)
\end{code}
Next we define a helper function that has an accessibility predicate on the
input. Eventually we lose the game as $\Floor{1 / 2} = 0$ and we can not call
the helper function on $0$ by assumption. Thankfully this lines up perfectly
with our desired base case.
\begin{code}
  âŸ¦_,_â‡‘âŸ§Ê° : âˆ€ (n : â„•) (acc : Acc _<_ n) {â‰¢0 : False (n â‰Ÿ 0)} â†’ ð”¹âº
  âŸ¦ suc n , acc down â‡‘âŸ§Ê° with suc n div 2
  ... | Euclideanâœ“ (suc q) 0 pf _ = âŸ¦ suc q , down (div-< (suc n) (suc q) 0 pf) â‡‘âŸ§Ê° 0áµ‡
  ... | Euclideanâœ“ zero    1 _ _ = ð•“1áµ‡
  ... | Euclideanâœ“ (suc q) 1 pf _ = âŸ¦ suc q , down (div-< (suc n) (suc q) 1 pf) â‡‘âŸ§Ê° 1áµ‡

  âŸ¦_â‡‘âŸ§âº : âˆ€ (n : â„•) {â‰¢0 : False (n â‰Ÿ 0)} â†’ ð”¹âº
  âŸ¦ suc n â‡‘âŸ§âº = âŸ¦ suc n , <-well-founded â‡‘âŸ§Ê°
\end{code}
\section{Binary Search}
\label{sec:binary-search}
Consider the following binary search for the value $10$ in the array
$
\rowarrowsep=-2pt
\begin{gmatrix}[b]
  1 & 5 & 8 & 10 & 11 & 20
\end{gmatrix}
$ depicted in equation \ref{eqn:binary-search}. The search starts with the bounds of the entire array
$\textcolor{blue}{[} 0, 5 \textcolor{blue}{]}$.
Then it updates the interval to the left half of the array
$\textcolor{green}{[} 3, 5 \textcolor{green}{]}$.
It finally narrows in on the correct answer the interval
$\textcolor{red}{[} 3, 3 \textcolor{red}{]}$.
As with all the examples described in this chapter this
algorithm terminates because the intervals are decreasing under a well-founded
relation, strict interval inclusion.
\begin{align}
  \label{eqn:binary-search}
  \begin{gmatrix}[b]
    \hspace{0.4em} \Line{blue} &
    1 &
    5 &
    8 &
    \Line{green} \hspace{0.4em} \Line{red} &
    10 &
    \Line{red} &
    11 &
    20 &
    \Line{green} \hspace{0.4em} \Line{blue} \hspace{0.4em}
  \end{gmatrix}
\end{align}
An interval $i_2$ strictly includes
an interval $i_1$ if $i_1$ is a proper subset of $i_2$. If the set is finite
then this relation is clearly well founded. Unfortunately working with sets is
tricky in a type theory. So we limit our definition of an
interval to sets of naturals. Then our intervals are uniquely represented by
their \textit{infimum} (lower bound) and \textit{supremum} (upper bound).
\begin{code}
  record Interval : Set where
    constructor [_,_âˆ£_]
    field
      inf : â„•
      sup : â„•
      infâ‰¤sup : inf â‰¤ sup
  open Interval
\end{code}
Now we have two bounds to manipulate so there are two possible ways to create an
interval smaller than another. Firstly to lower the supremum and secondly to
raise the infimum.
\begin{code}
  data _âŠ‚_ (iâ‚ : Interval) (iâ‚‚ : Interval) : Set where
    downward : inf iâ‚‚ â‰¤ inf iâ‚ â†’ sup iâ‚ < sup iâ‚‚ â†’ iâ‚ âŠ‚ iâ‚‚
    upward : inf iâ‚‚ < inf iâ‚ â†’ sup iâ‚ â‰¤ sup iâ‚‚ â†’ iâ‚ âŠ‚ iâ‚‚
\end{code}
Often authors prove termination for their binary search algorithm by instead
thinking about how the distance between the left and right bound decreases. We
adopt this technique to show that interval inclusion is a subrelation of
$\AgdaFunction{\_<\_}$. Although it is not technically a subrelation. It is a
subrelation generated by the function $\AgdaFunction{width}$.
\begin{code}
  width : Interval â†’ â„•
  width i = sup i âˆ¸ inf i

  âŠ‚â‡’< : âˆ€ {iâ‚ iâ‚‚} â†’ iâ‚ âŠ‚ iâ‚‚ â†’ width iâ‚ < width iâ‚‚
\end{code}
\begin{code}[hide]
  open import AKS.Unsafe using (trustMe)

  âˆ¸-monoË¡-< : âˆ€ {lâ‚ hâ‚ lâ‚‚ hâ‚‚} â†’ lâ‚ â‰¤ hâ‚ â†’ lâ‚‚ â‰¤ hâ‚‚ â†’ lâ‚‚ â‰¤ lâ‚ â†’ hâ‚ < hâ‚‚ â†’ hâ‚ âˆ¸ lâ‚ < hâ‚‚ âˆ¸ lâ‚‚
  âˆ¸-monoË¡-< {lâ‚} {hâ‚} {lâ‚‚} {hâ‚‚} lâ‚â‰¤hâ‚ lâ‚‚â‰¤hâ‚‚ lâ‚‚â‰¤lâ‚ hâ‚<hâ‚‚ = lte ((hâ‚‚ âˆ¸ lâ‚‚) âˆ¸ suc (hâ‚ âˆ¸ lâ‚)) trustMe

  âˆ¸-monoÊ³-< : âˆ€ {lâ‚ hâ‚ lâ‚‚ hâ‚‚} â†’ lâ‚ â‰¤ hâ‚ â†’ lâ‚‚ â‰¤ hâ‚‚ â†’ lâ‚‚ < lâ‚ â†’ hâ‚ â‰¤ hâ‚‚ â†’ hâ‚ âˆ¸ lâ‚ < hâ‚‚ âˆ¸ lâ‚‚
  âˆ¸-monoÊ³-< {lâ‚} {hâ‚} {lâ‚‚} {hâ‚‚} lâ‚â‰¤hâ‚ lâ‚‚â‰¤hâ‚‚ lâ‚‚<lâ‚ hâ‚â‰¤hâ‚‚ = lte ((hâ‚‚ âˆ¸ lâ‚‚) âˆ¸ suc (hâ‚ âˆ¸ lâ‚)) trustMe

  âŠ‚â‡’< {[ inf-iâ‚ , sup-iâ‚ âˆ£ inf-iâ‚â‰¤sup-iâ‚ ]} {[ inf-iâ‚‚ , sup-iâ‚‚ âˆ£ inf-iâ‚‚â‰¤sup-iâ‚‚ ]} (downward inf-iâ‚‚â‰¤inf-iâ‚ sup-iâ‚<sup-iâ‚‚)
    = âˆ¸-monoË¡-< inf-iâ‚â‰¤sup-iâ‚ inf-iâ‚‚â‰¤sup-iâ‚‚ inf-iâ‚‚â‰¤inf-iâ‚ sup-iâ‚<sup-iâ‚‚
  âŠ‚â‡’< {[ inf-iâ‚ , sup-iâ‚ âˆ£ inf-iâ‚â‰¤sup-iâ‚ ]} {[ inf-iâ‚‚ , sup-iâ‚‚ âˆ£ inf-iâ‚‚â‰¤sup-iâ‚‚ ]} (upward inf-iâ‚‚<inf-iâ‚ sup-iâ‚â‰¤sup-iâ‚‚)
    = âˆ¸-monoÊ³-< inf-iâ‚â‰¤sup-iâ‚ inf-iâ‚‚â‰¤sup-iâ‚‚ inf-iâ‚‚<inf-iâ‚ sup-iâ‚â‰¤sup-iâ‚‚
  -- âŠ‚â‡’< = BOTTOM
\end{code}
As the types of our elements are different we need to generalize
$\AgdaFunction{subrelation}$. We add a function to covert between the types.
Technically the function is a \textit{functor} \cite{awodey}
from the \textit{category} with $\AgdaFunction{\_â‰ºâ‚‚\_}$ as morphisms to the
category with $\AgdaFunction{\_â‰ºâ‚\_}$ as morphisms.
\begin{code}
  subrelation
      : âˆ€ {A : Set} {B : Set}
          {_â‰ºâ‚_ : A â†’ A â†’ Set}
          {_â‰ºâ‚‚_ : B â†’ B â†’ Set}
          {f : B â†’ A}
          {n : B}
      â†’ (âˆ€ {x y} â†’ x â‰ºâ‚‚ y â†’ f x â‰ºâ‚ f y)
      â†’ Acc _â‰ºâ‚_ (f n)
      â†’ Acc _â‰ºâ‚‚_ n
\end{code}
\begin{code}[hide]
  subrelation â‰ºâ‚‚â‡’â‰ºâ‚ (acc down) =
    acc Î» xâ‰ºâ‚‚n â†’ subrelation â‰ºâ‚‚â‡’â‰ºâ‚ (down (â‰ºâ‚‚â‡’â‰ºâ‚ xâ‰ºâ‚‚n))
\end{code}
Although we will not be implementing binary search in this thesis, this concept
will prove useful as it allows us to write terminating code that counts up to
some fixed value.
\begin{code}
  âŠ‚-well-founded : âˆ€ {i} â†’ Acc _âŠ‚_ i
  âŠ‚-well-founded = subrelation âŠ‚â‡’< <-well-founded

  count-up-to : â„• â†’ List â„•
  count-up-to n = loop 0 0â‰¤n âŠ‚-well-founded
\end{code}
\begin{code}[hide]
    where
\end{code}
Counting up is simply always choosing to tighten the left bound of the interval.
Eventually the user reaches the upper bound and interval becomes $[ n, n ]$.
This interval can not be shortened and the recursion terminates as shown below.
\begin{code}
    loop : âˆ€ (x : â„•) (xâ‰¤n : x â‰¤ n) (acc : Acc _âŠ‚_ [ x , n âˆ£ xâ‰¤n ]) â†’ List â„•
    loop x xâ‰¤n (acc next) with nâ‰¤mâ‡’n<mâˆ¨nâ‰¡m xâ‰¤n
    ... | orâ‚‚ xâ‰¡n = x âˆ· []
    ... | orâ‚ x<n = x âˆ· loop (1 + x) x<n (next [1+x,n]âŠ‚[x,n])
\end{code}
\begin{code}[hide]
      where
\end{code}
\begin{code}
      [1+x,n]âŠ‚[x,n] : [ 1 + x , n âˆ£ x<n ] âŠ‚ [ x , n âˆ£ xâ‰¤n ]
      [1+x,n]âŠ‚[x,n] = upward n<1+n â‰¤-refl
\end{code}
\begin{code}
  zero-to-three : count-up-to 3 â‰¡ 0 âˆ· 1 âˆ· 2 âˆ· 3 âˆ· []
  zero-to-three = â‰¡-refl
\end{code}

\end{document}
